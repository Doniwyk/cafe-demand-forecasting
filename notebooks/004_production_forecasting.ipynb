{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "REBRANDING_DATE = pd.to_datetime('2025-05-01')\n",
    "HOT_SEASON_MONTHS = [4, 5, 6, 7, 8, 9, 10]  # April-October (Indonesia)\n",
    "RAINY_SEASON_MONTHS = [11, 12, 1, 2, 3]  # November-March (Indonesia)\n",
    "FORECAST_DAYS = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionForecaster:\n",
    "    \"\"\"\n",
    "    Production model focused on performance evaluation (RF & GB only).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_type='rf'):\n",
    "        self.model_type = model_type\n",
    "        self.model = self._create_model()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.category_encoder = LabelEncoder()\n",
    "        self.feature_columns = []\n",
    "        self.items = []\n",
    "        self.item_categories = {}\n",
    "        \n",
    "    def _create_model(self):\n",
    "        \"\"\"Create the model architecture\"\"\"\n",
    "        if self.model_type == 'rf':\n",
    "            return RandomForestRegressor(\n",
    "                n_estimators=200,\n",
    "                max_depth=15,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                max_features=1.0,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif self.model_type == 'gb':\n",
    "            return GradientBoostingRegressor(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                subsample=0.8,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            return RandomForestRegressor(random_state=42) # Default\n",
    "    \n",
    "    def create_advanced_categories(self, df):\n",
    "        \"\"\"Create item categories for feature engineering\"\"\"\n",
    "        categories = {\n",
    "            'Coffee_Hot': ['kopi', 'cappucino', 'tubruk', 'drip', 'espresso'],\n",
    "            'Coffee_Cold': ['vietnam', 'ice', 'cold', 'frappe'],\n",
    "            'Tea': ['tea', 'teh'],\n",
    "            'Lemon': ['lemon'],\n",
    "            'Milk_Dairy': ['milk', 'susu', 'latte'],\n",
    "            'Food_Main': ['nasi', 'mie', 'ayam', 'sapi'],\n",
    "            'Food_Snack': ['kentang', 'cireng', 'basreng', 'tahu', 'tempe'],\n",
    "            'Food_Fried': ['goreng', 'fried'],\n",
    "            'Juice': ['juice', 'jus'],\n",
    "            'Other': []\n",
    "        }\n",
    "        \n",
    "        for item in df['Item'].unique():\n",
    "            item_lower = item.lower()\n",
    "            categorized = False\n",
    "            for category, keywords in categories.items():\n",
    "                if category == 'Other': continue\n",
    "                if any(keyword in item_lower for keyword in keywords):\n",
    "                    self.item_categories[item] = category\n",
    "                    categorized = True\n",
    "                    break\n",
    "            if not categorized:\n",
    "                self.item_categories[item] = 'Other'\n",
    "        return self.item_categories\n",
    "\n",
    "    def _create_date_features(self, date_series):\n",
    "        \"\"\"Standardized date features\"\"\"\n",
    "        date_features = {}\n",
    "        date_features['day_of_week'] = date_series.dt.dayofweek\n",
    "        date_features['day_of_month'] = date_series.dt.day\n",
    "        date_features['month'] = date_series.dt.month\n",
    "        date_features['quarter'] = date_series.dt.quarter\n",
    "        date_features['year'] = date_series.dt.year\n",
    "        date_features['week_of_year'] = date_series.dt.isocalendar().week\n",
    "        date_features['day_of_year'] = date_series.dt.dayofyear\n",
    "        \n",
    "        date_features['is_weekend'] = (date_features['day_of_week'] >= 5).astype(int)\n",
    "        date_features['is_monday'] = (date_features['day_of_week'] == 0).astype(int)\n",
    "        date_features['is_friday'] = (date_features['day_of_week'] == 4).astype(int)\n",
    "        \n",
    "        # Indonesia Seasons\n",
    "        HOT_SEASON = [4, 5, 6, 7, 8, 9, 10]\n",
    "        RAINY_SEASON = [11, 12, 1, 2, 3]\n",
    "        date_features['is_hot_season'] = date_features['month'].isin(HOT_SEASON).astype(int)\n",
    "        date_features['is_rainy_season'] = date_features['month'].isin(RAINY_SEASON).astype(int)\n",
    "        \n",
    "        date_features['is_month_start'] = (date_features['day_of_month'] <= 3).astype(int)\n",
    "        date_features['is_month_end'] = (date_features['day_of_month'] >= 28).astype(int)\n",
    "        \n",
    "        # Structural break\n",
    "        REBRANDING_DATE = pd.to_datetime('2025-05-01')\n",
    "        date_features['post_rebranding'] = (date_series >= REBRANDING_DATE).astype(int)\n",
    "        \n",
    "        return date_features\n",
    "\n",
    "    def prepare_production_features(self, df):\n",
    "        \"\"\"Feature engineering pipeline\"\"\"\n",
    "        df = df.copy()\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # Date Features\n",
    "        date_features = self._create_date_features(df['Date'])\n",
    "        for k, v in date_features.items(): df[k] = v\n",
    "        \n",
    "        # Categories\n",
    "        if not self.item_categories: self.create_advanced_categories(df)\n",
    "        df['category'] = df['Item'].map(self.item_categories)\n",
    "        \n",
    "        # Sort for lags\n",
    "        df = df.sort_values(['Item', 'Date'])\n",
    "        \n",
    "        # Lags & Rolling\n",
    "        grp = df.groupby('Item')['Quantity_Sold']\n",
    "        df['quantity_lag_1'] = grp.shift(1)\n",
    "        df['quantity_lag_7'] = grp.shift(7)\n",
    "        df['quantity_lag_14'] = grp.shift(14)\n",
    "        df['quantity_lag_30'] = grp.shift(30)\n",
    "        \n",
    "        df['rolling_mean_3'] = grp.transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "        df['rolling_std_3'] = grp.transform(lambda x: x.rolling(3, min_periods=1).std())\n",
    "        df['rolling_mean_7'] = grp.transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
    "        df['rolling_std_7'] = grp.transform(lambda x: x.rolling(7, min_periods=1).std())\n",
    "        df['rolling_mean_30'] = grp.transform(lambda x: x.rolling(30, min_periods=1).mean())\n",
    "        df['ewm_7'] = grp.transform(lambda x: x.ewm(span=7, adjust=False).mean())\n",
    "        \n",
    "        # Trend\n",
    "        df['trend_7'] = df['Quantity_Sold'] - df['rolling_mean_7']\n",
    "        \n",
    "        # Item Stats\n",
    "        item_stats = df.groupby('Item')['Quantity_Sold'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "        item_stats.columns = ['Item', 'item_mean', 'item_std', 'item_min', 'item_max']\n",
    "        df = df.merge(item_stats, on='Item', how='left')\n",
    "        \n",
    "        # Encodings\n",
    "        df['item_encoded'] = self.label_encoder.fit_transform(df['Item'])\n",
    "        df['category_encoded'] = self.category_encoder.fit_transform(df['category'])\n",
    "        \n",
    "        # Volatility\n",
    "        df['quantity_volatility'] = df['item_std'] / (df['item_mean'] + 1e-8)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def train(self, df, target_col='Quantity_Sold'):\n",
    "        \"\"\"Train model\"\"\"\n",
    "        df_features = self.prepare_production_features(df)\n",
    "        self.items = df['Item'].unique()\n",
    "        \n",
    "        feature_cols = [\n",
    "            'item_encoded', 'category_encoded', 'day_of_week', 'day_of_month', 'month', \n",
    "            'is_weekend', 'is_hot_season', 'post_rebranding',\n",
    "            'quantity_lag_1', 'quantity_lag_7', 'quantity_lag_14', 'quantity_lag_30',\n",
    "            'rolling_mean_3', 'rolling_std_3', 'rolling_mean_7', 'rolling_std_7', \n",
    "            'rolling_mean_30', 'ewm_7', 'trend_7',\n",
    "            'item_mean', 'item_std', 'item_min', 'item_max', 'quantity_volatility'\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        self.feature_columns = [c for c in feature_cols if c in df_features.columns]\n",
    "        \n",
    "        train_data = df_features.dropna(subset=self.feature_columns + [target_col])\n",
    "        X = train_data[self.feature_columns]\n",
    "        y = train_data[target_col].round().astype(int)\n",
    "        \n",
    "        if self.model is not None:\n",
    "            self.model.fit(X, y)\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict on feature matrix\"\"\"\n",
    "        if self.model is None: return np.zeros(len(X), dtype=int)\n",
    "        \n",
    "        X_clean = pd.DataFrame(X).fillna(0)\n",
    "        y_pred = self.model.predict(X_clean)\n",
    "        return np.maximum(np.round(y_pred), 0).astype(int)\n",
    "\n",
    "    def evaluate_on_split(self, train_df, test_df):\n",
    "        \"\"\"Train on train_df, evaluate on test_df, return metrics\"\"\"\n",
    "        # Train\n",
    "        self.train(train_df)\n",
    "        \n",
    "        # Prepare Test\n",
    "        test_feat = self.prepare_production_features(test_df)\n",
    "        test_clean = test_feat.dropna(subset=self.feature_columns + ['Quantity_Sold'])\n",
    "        \n",
    "        if len(test_clean) == 0:\n",
    "            return None\n",
    "            \n",
    "        X_test = test_clean[self.feature_columns]\n",
    "        y_test = test_clean['Quantity_Sold'].round().astype(int)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = self.predict(X_test)\n",
    "        \n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "        \n",
    "        return {\n",
    "            'mae': mae, \n",
    "            'rmse': rmse, \n",
    "            'mape': mape, \n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y_test.values,\n",
    "            'test_indices': test_clean.index\n",
    "        }\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Return feature importance DataFrame\"\"\"\n",
    "        if hasattr(self.model, 'feature_importances_'):\n",
    "            imps = self.model.feature_importances_\n",
    "            return pd.DataFrame({\n",
    "                'Feature': self.feature_columns,\n",
    "                'Importance': imps\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionEnsembleForecaster:\n",
    "    \"\"\"Evaluation-only Ensemble (RF + GB)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rf = ProductionForecaster('rf')\n",
    "        self.gb = ProductionForecaster('gb')\n",
    "        \n",
    "    def evaluate_ensemble(self, train_df, test_df):\n",
    "        \"\"\"Train both, predict both, average results, calculate metrics\"\"\"\n",
    "        print(\"   > Training RF...\")\n",
    "        rf_res = self.rf.evaluate_on_split(train_df, test_df)\n",
    "        \n",
    "        print(\"   > Training GB...\")\n",
    "        gb_res = self.gb.evaluate_on_split(train_df, test_df)\n",
    "        \n",
    "        if rf_res is None or gb_res is None:\n",
    "            return None\n",
    "            \n",
    "        # Ensemble Averaging\n",
    "        pred_rf = rf_res['y_pred']\n",
    "        pred_gb = gb_res['y_pred']\n",
    "        \n",
    "        # Simple Average Ensemble\n",
    "        ensemble_pred = np.round((pred_rf + pred_gb) / 2).astype(int)\n",
    "        y_true = rf_res['y_true'] # Same for both\n",
    "        \n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_true, ensemble_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, ensemble_pred))\n",
    "        mape = mean_absolute_percentage_error(y_true, ensemble_pred) * 100\n",
    "        \n",
    "        return {\n",
    "            'rf_metrics': rf_res,\n",
    "            'gb_metrics': gb_res,\n",
    "            'ensemble_metrics': {'mae': mae, 'rmse': rmse, 'mape': mape},\n",
    "            'rf_importance': self.rf.get_feature_importance()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL PERFORMANCE EVALUATION (RF vs GB vs ENSEMBLE)\n",
      "============================================================\n",
      "Total Records: 32447\n",
      "Train Set:     30408 records (Up to 2025-07-27)\n",
      "Test Set:      2039 records (Last 60 Days)\n",
      "------------------------------------------------------------\n",
      "   > Training RF...\n",
      "   > Training GB...\n",
      "\n",
      "=============================================\n",
      "PERFORMANCE METRICS SUMMARY (Test Set)\n",
      "=============================================\n",
      "Metric     | RF         | GB         | ENSEMBLE  \n",
      "---------------------------------------------\n",
      "MAE        | 0.012      | 0.000      | 0.012     \n",
      "RMSE       | 0.109      | 0.000      | 0.109     \n",
      "MAPE       | 0.12      % | 0.00      % | 0.12      %\n",
      "---------------------------------------------\n",
      "\n",
      "üèÜ Best Performing Model: Gradient Boosting\n",
      "\n",
      "=============================================\n",
      "TOP 10 DRIVERS OF ACCURACY (RF Importance)\n",
      "=============================================\n",
      "        Feature  Importance\n",
      "        trend_7    0.734002\n",
      "  rolling_std_3    0.071944\n",
      "  rolling_std_7    0.068865\n",
      " rolling_mean_7    0.065041\n",
      "          ewm_7    0.050888\n",
      " rolling_mean_3    0.007530\n",
      "       item_std    0.000386\n",
      "       item_max    0.000385\n",
      "rolling_mean_30    0.000146\n",
      "    day_of_week    0.000133\n"
     ]
    }
   ],
   "source": [
    "def run_performance_evaluation():\n",
    "    \"\"\"Run comprehensive model performance evaluation\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODEL PERFORMANCE EVALUATION (RF vs GB vs ENSEMBLE)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    base_path = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "    data_path = os.path.join(base_path, 'data', 'processed', 'daily_item_sales.csv')\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Error: Data file not found.\")\n",
    "        return\n",
    "        \n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # 2. Split Data (Train / Test)\n",
    "    # Strategy: Use last 60 days as Holdout Test Set\n",
    "    cutoff_date = df['Date'].max() - timedelta(days=60)\n",
    "    \n",
    "    train_df = df[df['Date'] <= cutoff_date].copy()\n",
    "    test_df = df[df['Date'] > cutoff_date].copy()\n",
    "    \n",
    "    print(f\"Total Records: {len(df)}\")\n",
    "    print(f\"Train Set:     {len(train_df)} records (Up to {cutoff_date.date()})\")\n",
    "    print(f\"Test Set:      {len(test_df)} records (Last 60 Days)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 3. Run Evaluation\n",
    "    ensemble = ProductionEnsembleForecaster()\n",
    "    results = ensemble.evaluate_ensemble(train_df, test_df)\n",
    "    \n",
    "    if results is None:\n",
    "        print(\"Evaluation failed (insufficient data for features in test set).\")\n",
    "        return\n",
    "\n",
    "    # 4. Print Summary Table\n",
    "    rf = results['rf_metrics']\n",
    "    gb = results['gb_metrics']\n",
    "    ens = results['ensemble_metrics']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(\"PERFORMANCE METRICS SUMMARY (Test Set)\")\n",
    "    print(\"=\"*45)\n",
    "    print(f\"{'Metric':<10} | {'RF':<10} | {'GB':<10} | {'ENSEMBLE':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"{'MAE':<10} | {rf['mae']:<10.3f} | {gb['mae']:<10.3f} | {ens['mae']:<10.3f}\")\n",
    "    print(f\"{'RMSE':<10} | {rf['rmse']:<10.3f} | {gb['rmse']:<10.3f} | {ens['rmse']:<10.3f}\")\n",
    "    print(f\"{'MAPE':<10} | {rf['mape']:<10.2f}% | {gb['mape']:<10.2f}% | {ens['mape']:<10.2f}%\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    best_model = \"Ensemble\"\n",
    "    if rf['mae'] < ens['mae'] and rf['mae'] < gb['mae']: best_model = \"Random Forest\"\n",
    "    if gb['mae'] < ens['mae'] and gb['mae'] < rf['mae']: best_model = \"Gradient Boosting\"\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Performing Model: {best_model}\")\n",
    "\n",
    "    # 5. Feature Importance Analysis (RF)\n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(\"TOP 10 DRIVERS OF ACCURACY (RF Importance)\")\n",
    "    print(\"=\"*45)\n",
    "    imp_df = results['rf_importance']\n",
    "    if not imp_df.empty:\n",
    "        print(imp_df.head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"Feature importance not available.\")\n",
    "\n",
    "# Execute\n",
    "run_performance_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cafe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
